# app/services/llm_client.py
import os
import logging
from typing import Dict, Any, List

import httpx

from app.schemas.review import LLMRequest, LLMResponse, CategoryResult
from app.routers.ws_debug import ws_manager  # WebSocket manager

logger = logging.getLogger(__name__)

# ğŸ”§ LLM í’ˆì§ˆ API ì—”ë“œí¬ì¸íŠ¸ (ì„œë²„: 8001)
#   .env ì—ì„œ ë®ì–´ì“°ë©´ ë¨:
#   LLM_QUALITY_API_URL=http://18.205.229.159:8001/api/v1/review/
LLM_QUALITY_API_URL = os.getenv(
    "LLM_QUALITY_API_URL",
    "http://18.205.229.159:8001/api/v1/review/",
).rstrip("/")

# --------------------------------------------------------
# ë”ë¯¸ ì‘ë‹µ (LLM ì„œë²„ ì£½ì—ˆì„ ë•Œë§Œ ì‚¬ìš©)
# --------------------------------------------------------
def build_dummy_llm_response() -> LLMResponse:
    dummy_scores = {"global": 50.0, "model": 50.0}
    dummy_categories = [
        CategoryResult(
            name="bug",
            score=50.0,
            comment="LLM ì„œë²„ í˜¸ì¶œ ì‹¤íŒ¨ë¡œ ë”ë¯¸ ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.",
        ),
        CategoryResult(
            name="maintainability",
            score=50.0,
            comment="LLM ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•Šì•„ ì‹¤ì œ í‰ê°€ëŠ” ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
        ),
    ]
    dummy_summary = "LLM ì„œë²„ ì˜¤ë¥˜ë¡œ ì¸í•´ ì‹¤ì œ ì½”ë“œ ë¦¬ë·° ëŒ€ì‹  ë”ë¯¸ ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."

    return LLMResponse(
        scores=dummy_scores,
        categories=dummy_categories,
        summary=dummy_summary,
    )


# --------------------------------------------------------
# í•µì‹¬ í•¨ìˆ˜: 8000 â†’ 8001 í’ˆì§ˆ API í˜¸ì¶œ
# --------------------------------------------------------
async def review_code(llm_req: LLMRequest) -> LLMResponse:

    # 1) ì½”ë“œ ì¶”ì¶œ
    code = getattr(llm_req, "code", None) or getattr(llm_req, "input", None)
    if not code:
        logger.error("[LLM] ì½”ë“œê°€ ë¹„ì–´ì„œ ë¦¬ë·°ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return build_dummy_llm_response()

    # WebSocket ë””ë²„ê·¸ ë¡œê·¸
    if ws_manager:
        try:
            await ws_manager.broadcast(
                {
                    "event": "llm_request_sent",
                    "step": 3,
                    "payload": {
                        "target": "quality_api",
                        "url": f"{LLM_QUALITY_API_URL}/",
                        "has_code": bool(code),
                    },
                }
            )
        except Exception:
            pass

    # 2) ìš”ì²­ payload (ë¬¸ì œì—ì„œ ì¤€ ìŠ¤í™ ê·¸ëŒ€ë¡œ)
    request_payload: Dict[str, Any] = {
        "code_snippet": code,
    }

    fallback = False
    data: Dict[str, Any] | None = None

    # 3) HTTP í˜¸ì¶œ
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            resp = await client.post(f"{LLM_QUALITY_API_URL}/", json=request_payload)
        # ìƒíƒœ ì½”ë“œ í™•ì¸
        if resp.status_code >= 400:
            fallback = True
            logger.error(
                f"[LLM] quality API HTTP {resp.status_code} ì—ëŸ¬: {resp.text}"
            )
        else:
            # JSON íŒŒì‹±
            data = resp.json()
            logger.info(f"[LLM] quality API response: {data}")
            # ë””ë²„ê·¸ìš© ì›ë³¸ ì¶œë ¥ (í„°ë¯¸ë„ì—ì„œ ë°”ë¡œ ë³´ë ¤ê³ )
            print("[LLM] RAW RESPONSE:", data)
    except Exception as e:
        logger.error(f"[LLM] quality API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        fallback = True

    # 4) ì‘ë‹µ íŒŒì‹± â†’ ë‚´ë¶€ LLMResponse ë¡œ ë³€í™˜
    if not fallback and isinstance(data, dict):
        try:
            quality_score = float(data.get("quality_score", 0.0))
            review_summary = (data.get("review_summary") or "").strip()

            scores_by_category_raw = data.get("scores_by_category") or {}
            review_details = data.get("review_details") or {}

            scores_dict = {
                "global": quality_score,
                "model": quality_score,
            }

            categories: List[CategoryResult] = []

            # dict í˜•íƒœ: { "bug": 70.0, ... }
            if isinstance(scores_by_category_raw, dict):
                for name, score in scores_by_category_raw.items():
                    name_str = str(name)
                    try:
                        score_val = float(score)
                    except Exception:
                        score_val = 0.0
                    comment = ""
                    if isinstance(review_details, dict):
                        comment = review_details.get(name_str, "") or ""
                    categories.append(
                        CategoryResult(
                            name=name_str,
                            score=score_val,
                            comment=comment,
                        )
                    )

            # list í˜•íƒœ: [ {"name": "...", "score": ...}, ... ] ë„ ì§€ì›
            elif isinstance(scores_by_category_raw, list):
                for item in scores_by_category_raw:
                    if not isinstance(item, dict):
                        continue
                    name_str = str(item.get("name", ""))
                    try:
                        score_val = float(item.get("score", 0.0))
                    except Exception:
                        score_val = 0.0
                    comment = item.get("comment") or ""
                    if not comment and isinstance(review_details, dict):
                        comment = review_details.get(name_str, "") or ""
                    categories.append(
                        CategoryResult(
                            name=name_str,
                            score=score_val,
                            comment=comment,
                        )
                    )

            # íŒŒì‹±ëœ ê±¸ë¡œ ìµœì¢… LLMResponse ìƒì„±
            llm_resp = LLMResponse(
                scores=scores_dict,
                categories=categories,
                summary=review_summary or "LLM í’ˆì§ˆ APIì—ì„œ ìš”ì•½ì„ ì œê³µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            )
        except Exception as e:
            # íŒŒì‹±ë§Œ ì‹¤íŒ¨í–ˆìœ¼ë©´ ê·¸ëƒ¥ ë”ë¯¸ë¡œ í´ë°±
            logger.error(f"[LLM] ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            fallback = True
            llm_resp = build_dummy_llm_response()
    else:
        llm_resp = build_dummy_llm_response()

    # WebSocket ë””ë²„ê·¸ ë¡œê·¸
    if ws_manager:
        try:
            await ws_manager.broadcast(
                {
                    "event": "llm_response_received",
                    "step": 4,
                    "payload": {
                        "from": "quality_api",
                        "scores": llm_resp.scores,
                        "category_count": len(llm_resp.categories),
                        "fallback": fallback,
                    },
                }
            )
        except Exception:
            pass

    return llm_resp
