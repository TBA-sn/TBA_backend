import openai
import json_repair
import re
import os

class CodeReviewerClient:
    """
    vLLM ì—”ì§„(8001ë²ˆ í¬íŠ¸)ê³¼ í†µì‹ í•˜ì—¬ AI ì½”ë“œ ë¦¬ë·° ë° ìˆ˜ì • ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    
    def __init__(self, vllm_url="http://localhost:8001/v1"):
        """
        í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        :param vllm_url: vLLM ì„œë²„ ì£¼ì†Œ (ê¸°ë³¸ê°’: ë¡œì»¬ 8001ë²ˆ í¬íŠ¸)
        """
        # vLLMì€ OpenAI SDKì™€ í˜¸í™˜ë©ë‹ˆë‹¤. API í‚¤ëŠ” ë¡œì»¬ì´ë¼ í•„ìš” ì—†ì§€ë§Œ í˜•ì‹ìƒ 'EMPTY'ë¥¼ ë„£ìŠµë‹ˆë‹¤.
        self.client = openai.OpenAI(base_url=vllm_url, api_key="EMPTY")
        
        # start_vllm.shì—ì„œ ì„¤ì •í•œ ëª¨ë¸ ì´ë¦„ (--served-model-name)
        self.model_name = "deepseek-v3" 

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ë¦¬ë·°ìš© vs ìˆ˜ì •ìš©)
        self.REVIEW_SYS_PROMPT = (
            "You are an expert Python code reviewer. "
            "Your task is to analyze Python code based on 4 criteria "
            "(bug, maintainability, style, security) and return the results in JSON format."
        )

        self.FIX_SYS_PROMPT = (
            "You are an expert Python Software Architect. "
            "Your ONLY job is to REFACTOR and FIX the given Python code "
            "based on the Review Report, and RETURN ONLY THE FINAL PYTHON CODE. "
            "Do NOT return JSON. Do NOT return any explanation. "
            "Only return Python source code."
        )

    def get_review(self, code_snippet: str) -> dict:
        """
        [ê¸°ëŠ¥ 1] ì½”ë“œ ë¦¬ë·° ìš”ì²­
        """
        user_prompt = (
            "[INST]\n"
            "Please review the following Python code based on 4 criteria "
            "and provide the results in the specified JSON format.\n"
            "The JSON MUST STRICTLY adhere to the following structure, including 'quality_score', "
            "'review_summary', 'scores_by_category', and 'review_details'.\n"
            "Example scores_by_category structure: "
            "{\"bug\": 90, \"maintainability\": 70, \"style\": 60, \"security\": 80}\n\n"
            f"[CODE]\n{code_snippet}\n[/CODE]\n"
            "[/INST]"
        )
        
        output_text = self._call_vllm(self.REVIEW_SYS_PROMPT, user_prompt)
        
        if "[/INST]" in output_text:
            output_text = output_text.split("[/INST]")[-1].strip()
        
        review_json = json_repair.loads(output_text)
        
        if "scores_by_category" not in review_json:
            review_json["scores_by_category"] = {
                "bug": 0, "maintainability": 0, "style": 0, "security": 0
            }
             
        return review_json

    def get_fix(self, code_snippet: str, review_summary: str, review_details: dict) -> str:
        """
        [ê¸°ëŠ¥ 2] ìˆ˜ì • ì½”ë“œ ì œì•ˆ
        """
        review_context = f"Summary: {review_summary}\nDetails: {review_details}"

        # âœ… JSON ì ˆëŒ€ ê¸ˆì§€ + ì½”ë“œë¸”ë¡ ê°•ì œ
        user_prompt = (
            "[INST]\n"
            "You will be given some original Python code and a Review Report.\n"
            "Your job is to RETURN ONLY THE FINAL REFACTORED PYTHON CODE.\n\n"
            f"[ORIGINAL CODE]\n{code_snippet}\n\n"
            f"[REVIEW REPORT TO FIX]\n{review_context}\n\n"
            "Strictly follow these rules:\n"
            "1. Fix bugs and security issues mentioned in the report.\n"
            "2. IMPROVE MAINTAINABILITY: Reduce Cyclomatic Complexity, "
            "   split long functions into well-named helper functions, "
            "   and reduce deep nesting using guard clauses where appropriate.\n"
            "3. Apply PEP 8, Type Hints, and Docstrings.\n"
            "4. VERY IMPORTANT:\n"
            "   - NEVER output JSON.\n"
            "   - NEVER output any natural language explanation.\n"
            "   - Return ONLY ONE Markdown code block with the final refactored code,\n"
            "     formatted exactly as:\n"
            "     ```python\n"
            "     # your code here\n"
            "     ```\n"
            "[/INST]"
        )
        
        output_text = self._call_vllm(self.FIX_SYS_PROMPT, user_prompt)

        # ë””ë²„ê¹…í•˜ê³  ì‹¶ìœ¼ë©´ ì ê¹ ì—´ì–´ë´ë„ ë¨
        # print("RAW FIX OUTPUT:", output_text[:300])

        if "[/INST]" in output_text:
            output_text = output_text.split("[/INST]")[-1].strip()
            
        # ```python / ```py / ``` ì½”ë“œë¸”ë¡ ìš°ì„  ì¶”ì¶œ
        code_match = re.search(r'```(?:python|py)?\s*(.*?)\s*```', output_text, re.DOTALL)
        if code_match:
            fixed_code = code_match.group(1).strip()
        else:
            # ì½”ë“œë¸”ë¡ì´ ì—†ìœ¼ë©´ ë°±í‹±ë§Œ ë‚ ë¦¬ê³  ì‚¬ìš©
            fixed_code = output_text.replace("```", "").strip()
        
        # ğŸ§± ë°©ì–´: ë˜ JSON ë±‰ìœ¼ë©´ ì—¬ê¸°ì„œ ì»·
        if fixed_code.lstrip().startswith("{"):
            raise RuntimeError(
                "AI returned JSON instead of refactored code in get_fix. "
                "Check vLLM model / prompt configuration."
            )
        
        return fixed_code

    def _call_vllm(self, system_msg, user_msg):
        """
        vLLM ì„œë²„ë¡œ ì‹¤ì œ HTTP ìš”ì²­ì„ ë³´ë‚´ëŠ” ë‚´ë¶€ í•¨ìˆ˜
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": user_msg}
                ],
                max_tokens=2048,
                temperature=0.0,
                stop=["<|EOT|>", "[/INST]"]
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f" vLLM Connection Error: {e}")
            raise RuntimeError("AI Engine (vLLM) is currently unavailable. Please check port 8001.")
